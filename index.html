<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="description" content="CHRIS: Clothed Human Reconstruction with Side View Consistency">
    <meta name="keywords" content="3D Human Reconstruction">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CHRIS: Clothed Human Reconstruction with Side View Consistency</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <script defer src="./static/js/fontawesome.all.min.js"></script>

    <!-- MathJax script for LaTeX -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">CHRIS: Clothed Human Reconstruction with Side View Consistency</h1>
                    </div>
                </div>
            </div>
        </div>
    </section>
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
          <span class=FocalGaussian></span> Our CHRIS reconstructs complex scenarios (loose clothing and challenging poses) and detailed geometry (such as hairs and wrinkles). </span>
        </h2>
        <figure class="image">
          <img src="static/images/vs.jpg"
            alt="Comparisons with recent advances in in-the-wild images"
            style="width:100%; height:auto;">
        </figure>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Creating a realistic clothed human from a single-view RGB image is crucial for applications in mixed reality, and filmmaking.
            </p>
            <p>
              Despite some progress in recent years, mainstream methods often fail to fully utilize side-view information, as the input single-view image contains front-view information only. This leads to globally unrealistic topology and local surface inconsistencies in side views.
            </p>
            <p>
              To address these, we introduce Clothed Human Reconstruction with Side View Consistency, namely CHRIS, which consists of 1) A Side-View Normal Discriminator that enhances global visual reasonability by distinguishing the generated side-view normals from the ground truth ones; 2) A Multi-to-one gradient computation (M2O) that ensures local surface consistency. M2O calculates the gradient of a sampling point by integrating the gradients of the nearby points, effectively acting as a smooth operation.
            </p>
            <p>Experimental results demonstrate that CHRIS outperforms the state-of-the-art methods by 5.5% and 4.2% in terms of P2S measurement on the THuman2.0 and CAPE datasets, respectively.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
      <!-- <img src="static/myvideos/overview.png" alt="Descriptive text about the image" style="width:100%; height:auto;"> -->

    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <!-- Image and Text within the same column wrapper -->
          <figure class="image">
            <img src="static/myvideos/overview.png"
              alt="Overview of the FocalGaussian process showing how a 3D avatar is created from a text prompt"
              style="width:100%; height:auto;">
          </figure>
          <div class="content has-text-justified">
            <p>
              Overview of our CHRIS. Conditioned on a single-view image I and the corresponding SMPL-X M, we sample 3D points P, obtaining their features regarding the geometry of the 3D clothed human. Then, we obtain the SDF Sˆ and the corresponding side-view normal maps ˆN c w.r.t. the clothed human from I. To improve the global side-view geometry, we introduce a Side-View Normal Discriminator that distinguishes between ˆNc and ground truth normal maps. Moreover, to enhance local surface consistency, we employ a multi-to-one gradient computation combined with a coarse-to-fine strategy. By integrating the gradients of nearby points around p, we smooth out local irregularities, leading to consistent surface reconstruction.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Animation Examples</h2>
          <!-- Image and Text within the same column wrapper -->
          <figure class="image">
            <img src="static/myvideos/overview.png"
              alt="Overview of the FocalGaussian process showing how a 3D avatar is created from a text prompt"
              style="width:100%; height:auto;">
          </figure>
          <div class="content has-text-justified">
            <p>
              We demomstrate the animation of 3D clothed human reconstructed by our CHRIS. With the single mesh and the motion series, we are able to generate animatable video. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Re-rendering. -->
      <h3 class="title is-4 has-text-centered">Effects of Focal Depth Loss</h3>
      <div class="content has-text-justified">
      </div>
      <div class="content has-text-centered">
        <video id="replay-video" autoplay controls muted loop playsinline style="width:100%; height:auto;">
          <source src="static/myvideos/lambda1_focaldepthloss.mp4" type="video/mp4">
        </video>
        <img src="static/myvideos/lossratio.png"
          alt="Graph showing the effects of different loss ratios on hand recovery clarity"
          style="width:100%; height:auto;">
        <p>
          
        </p>
      </div>
      <!--/ Re-rendering. -->
    </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is borrowed from the <a href="https://github.com/nerfies/nerfies.github.io">source code</a>
              of Nerfies under the license of a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>